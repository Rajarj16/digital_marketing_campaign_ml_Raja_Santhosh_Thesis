{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB-wKAvQXSAO"
      },
      "outputs": [],
      "source": [
        "# PART 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for professional visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")"
      ],
      "metadata": {
        "id": "1kKwYx4OYFa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DIGITAL MARKETING CAMPAIGN PERFORMANCE ANALYSIS\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/Social Media Engagement Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"Dataset loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "4_qX7dEEYFdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 2: INITIAL DATA EXPLORATION\n",
        "\n",
        "print(\"\\nINITIAL DATA EXPLORATION\")\n",
        "\n",
        "print(\"\\nDataset Structure:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n\\nBasic Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n\\nMissing Values:\")\n",
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(missing[missing > 0])\n",
        "else:\n",
        "    print(\"No missing values found\")\n",
        "\n",
        "print(\"\\n\\nDuplicate Rows:\", df.duplicated().sum())"
      ],
      "metadata": {
        "id": "-Rku4ISDYFgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 3: DATA PREPROCESSING\n",
        "\n",
        "print(\"DATA PREPROCESSING\")\n",
        "\n",
        "# Convert timestamp to datetime\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['month'] = df['timestamp'].dt.month\n",
        "\n",
        "# Create derived features with business logic\n",
        "df['total_interactions'] = df['likes_count'] + df['shares_count'] + df['comments_count']\n",
        "df['virality_score'] = df['shares_count'] / (df['likes_count'] + 1)\n",
        "df['comment_rate'] = df['comments_count'] / (df['impressions'] + 1)\n",
        "df['share_rate'] = df['shares_count'] / (df['impressions'] + 1)\n",
        "df['like_rate'] = df['likes_count'] / (df['impressions'] + 1)\n",
        "\n",
        "# Interaction terms (campaign phase with sentiment)\n",
        "df['sentiment_x_past_avg'] = df['sentiment_score'] * df['user_past_sentiment_avg']\n",
        "\n",
        "print(\"Temporal features extracted\")\n",
        "print(\"Engagement metrics derived\")\n",
        "print(\"Interaction terms created\")\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_cols = ['platform', 'language', 'topic_category', 'sentiment_label',\n",
        "                   'emotion_type', 'brand_name', 'campaign_phase']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[f'{col}_encoded'] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\" {len(categorical_cols)} categorical variables encoded\")"
      ],
      "metadata": {
        "id": "LGra4q30YFjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 4: EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "# Key metrics summary\n",
        "print(\"\\nEngagement Metrics Summary:\")\n",
        "engagement_metrics = ['engagement_rate', 'likes_count', 'shares_count',\n",
        "                     'comments_count', 'impressions']\n",
        "print(df[engagement_metrics].describe())\n",
        "\n",
        "# Distribution analysis\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Distribution of Key Engagement Metrics', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_to_plot = ['engagement_rate', 'likes_count', 'shares_count',\n",
        "                   'comments_count', 'impressions', 'sentiment_score']\n",
        "\n",
        "for idx, metric in enumerate(metrics_to_plot):\n",
        "    row, col = idx // 3, idx % 3\n",
        "    axes[row, col].hist(df[metric], bins=50, edgecolor='black', alpha=0.7)\n",
        "    axes[row, col].set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
        "    axes[row, col].set_xlabel('Value')\n",
        "    axes[row, col].set_ylabel('Frequency')\n",
        "\n",
        "    # Add skewness info\n",
        "    skew = df[metric].skew()\n",
        "    axes[row, col].text(0.7, 0.9, f'Skew: {skew:.2f}',\n",
        "                       transform=axes[row, col].transAxes,\n",
        "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Distribution analysis completed\")\n",
        "plt.show()\n",
        "\n",
        "# Campaign performance by platform\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "platform_engagement = df.groupby('platform')['engagement_rate'].agg(['mean', 'std', 'count'])\n",
        "platform_engagement = platform_engagement.sort_values('mean', ascending=False)\n",
        "\n",
        "axes[0].bar(platform_engagement.index, platform_engagement['mean'],\n",
        "           yerr=platform_engagement['std'], capsize=5, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title('Average Engagement Rate by Platform', fontweight='bold')\n",
        "axes[0].set_xlabel('Platform')\n",
        "axes[0].set_ylabel('Engagement Rate')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Campaign phase performance\n",
        "phase_engagement = df.groupby('campaign_phase')['engagement_rate'].agg(['mean', 'std'])\n",
        "phase_engagement = phase_engagement.sort_values('mean', ascending=False)\n",
        "\n",
        "axes[1].bar(phase_engagement.index, phase_engagement['mean'],\n",
        "           yerr=phase_engagement['std'], capsize=5, alpha=0.7,\n",
        "           color='coral', edgecolor='black')\n",
        "axes[1].set_title('Average Engagement Rate by Campaign Phase', fontweight='bold')\n",
        "axes[1].set_xlabel('Campaign Phase')\n",
        "axes[1].set_ylabel('Engagement Rate')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('platform_phase_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Platform and campaign phase analysis completed\")\n",
        "plt.show()\n",
        "\n",
        "# Sentiment impact analysis\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sentiment_engagement = df.groupby('sentiment_label')['engagement_rate'].mean().sort_values()\n",
        "axes[0].barh(sentiment_engagement.index, sentiment_engagement.values, alpha=0.7, edgecolor='black')\n",
        "axes[0].set_title('Engagement Rate by Sentiment', fontweight='bold')\n",
        "axes[0].set_xlabel('Average Engagement Rate')\n",
        "\n",
        "# Emotion impact\n",
        "emotion_engagement = df.groupby('emotion_type')['engagement_rate'].mean().sort_values()\n",
        "axes[1].barh(emotion_engagement.index, emotion_engagement.values,\n",
        "            alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[1].set_title('Engagement Rate by Emotion Type', fontweight='bold')\n",
        "axes[1].set_xlabel('Average Engagement Rate')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sentiment_emotion_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Sentiment and emotion analysis completed\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "72Ke5z5kYFmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 5: CORRELATION ANALYSIS\n",
        "\n",
        "print(\"CORRELATION ANALYSIS\")\n",
        "\n",
        "# Select numeric features for correlation\n",
        "numeric_features = ['sentiment_score', 'toxicity_score', 'likes_count', 'shares_count',\n",
        "                   'comments_count', 'impressions', 'engagement_rate',\n",
        "                   'user_past_sentiment_avg', 'user_engagement_growth', 'buzz_change_rate',\n",
        "                   'hour', 'month', 'virality_score', 'total_interactions']\n",
        "\n",
        "correlation_matrix = df[numeric_features].corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f',\n",
        "           cmap='coolwarm', center=0, square=True, linewidths=1,\n",
        "           cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Numeric Features', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Correlation matrix generated\")\n",
        "plt.show()\n",
        "\n",
        "# Identify high correlations with engagement_rate\n",
        "eng_correlations = correlation_matrix['engagement_rate'].sort_values(ascending=False)\n",
        "print(\"\\nTop 10 Features Correlated with Engagement Rate:\")\n",
        "print(eng_correlations.head(10))"
      ],
      "metadata": {
        "id": "spXBwPt8YFpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 6: FEATURE SELECTION AND PREPARATION\n",
        "\n",
        "print(\"FEATURE SELECTION AND PREPARATION\")\n",
        "\n",
        "# Define target variable\n",
        "target = 'engagement_rate'\n",
        "\n",
        "# Select features for modeling\n",
        "feature_candidates = [\n",
        "    'sentiment_score', 'toxicity_score', 'likes_count', 'shares_count',\n",
        "    'comments_count', 'impressions', 'user_past_sentiment_avg',\n",
        "    'user_engagement_growth', 'buzz_change_rate', 'hour', 'month',\n",
        "    'platform_encoded', 'language_encoded', 'topic_category_encoded',\n",
        "    'sentiment_label_encoded', 'emotion_type_encoded', 'brand_name_encoded',\n",
        "    'campaign_phase_encoded', 'virality_score', 'sentiment_x_past_avg'\n",
        "]\n",
        "\n",
        "X = df[feature_candidates].copy()\n",
        "y = df[target].copy()\n",
        "\n",
        "# Check for multicollinearity using VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data.sort_values('VIF', ascending=False)\n",
        "\n",
        "print(\"\\nVariance Inflation Factor (VIF) Analysis:\")\n",
        "print(\"(VIF > 10 indicates high multicollinearity)\")\n",
        "vif_results = calculate_vif(X)\n",
        "print(vif_results.head(10))\n",
        "\n",
        "# Remove features with extreme VIF (>10)\n",
        "high_vif_features = vif_results[vif_results['VIF'] > 10]['Feature'].tolist()\n",
        "if high_vif_features:\n",
        "    print(f\"\\n Removing {len(high_vif_features)} features with VIF > 10:\")\n",
        "    print(high_vif_features)\n",
        "    # Keep essential features but remove redundant ones\n",
        "    features_to_remove = [f for f in high_vif_features if f not in ['impressions', 'sentiment_score']]\n",
        "    X = X.drop(columns=features_to_remove, errors='ignore')\n",
        "\n",
        "print(f\"\\nFinal feature set: {X.shape[1]} features\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled using StandardScaler\")"
      ],
      "metadata": {
        "id": "ZoiU62G9YFr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 7: MODEL BUILDING AND COMPARISON\n",
        "\n",
        "print(\"MODEL BUILDING AND COMPARISON\")\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Lasso Regression': Lasso(alpha=0.01),\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train_scaled)\n",
        "    y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5,\n",
        "                                scoring='r2', n_jobs=-1)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Train R²': train_r2,\n",
        "        'Test R²': test_r2,\n",
        "        'CV R² Mean': cv_scores.mean(),\n",
        "        'CV R² Std': cv_scores.std(),\n",
        "        'RMSE': test_rmse,\n",
        "        'MAE': test_mae\n",
        "    })\n",
        "\n",
        "    print(f\"  Train R²: {train_r2:.4f}\")\n",
        "    print(f\"  Test R²: {test_r2:.4f}\")\n",
        "    print(f\"  CV R² (5-fold): {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "    print(f\"  RMSE: {test_rmse:.6f}\")\n",
        "    print(f\"  MAE: {test_mae:.6f}\")\n",
        "\n",
        "# Display results table\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# R² comparison\n",
        "axes[0].bar(results_df['Model'], results_df['Test R²'], alpha=0.7, edgecolor='black')\n",
        "axes[0].axhline(y=0.5, color='r', linestyle='--', label='Target R² = 0.5')\n",
        "axes[0].set_title('Model Performance Comparison (R²)', fontweight='bold')\n",
        "axes[0].set_ylabel('R² Score')\n",
        "axes[0].set_xlabel('Model')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].legend()\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# RMSE comparison\n",
        "axes[1].bar(results_df['Model'], results_df['RMSE'], alpha=0.7,\n",
        "           color='coral', edgecolor='black')\n",
        "axes[1].set_title('Model Error Comparison (RMSE)', fontweight='bold')\n",
        "axes[1].set_ylabel('RMSE')\n",
        "axes[1].set_xlabel('Model')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n Model comparison visualization saved\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8eLF6KyvYFuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 8: REGRESSION ASSUMPTIONS TESTING (BEST MODEL)\n",
        "\n",
        "print(\"REGRESSION ASSUMPTIONS TESTING\")\n",
        "\n",
        "# Select best model (highest test R²)\n",
        "best_model_name = results_df.loc[results_df['Test R²'].idxmax(), 'Model']\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\nBest performing model: {best_model_name}\")\n",
        "print(f\"Test R²: {results_df.loc[results_df['Test R²'].idxmax(), 'Test R²']:.4f}\")\n",
        "\n",
        "# Get predictions from best model\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Create diagnostic plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle(f'Regression Diagnostics - {best_model_name}',\n",
        "            fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Residuals vs Fitted (Linearity and Homoscedasticity)\n",
        "axes[0, 0].scatter(y_pred, residuals, alpha=0.5)\n",
        "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Fitted Values')\n",
        "axes[0, 0].set_ylabel('Residuals')\n",
        "axes[0, 0].set_title('Residuals vs Fitted Values\\n(Check Linearity & Homoscedasticity)')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Add lowess smoothing line\n",
        "from scipy.signal import savgol_filter\n",
        "try:\n",
        "    sorted_idx = np.argsort(y_pred)\n",
        "    smoothed = savgol_filter(residuals[sorted_idx], window_length=51, polyorder=3)\n",
        "    axes[0, 0].plot(y_pred[sorted_idx], smoothed, 'g-', linewidth=2, label='Trend')\n",
        "    axes[0, 0].legend()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. Q-Q Plot (Normality)\n",
        "from scipy import stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('Q-Q Plot\\n(Check Normality of Residuals)')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# 3. Scale-Location Plot (Homoscedasticity)\n",
        "standardized_residuals = np.sqrt(np.abs((residuals - residuals.mean()) / residuals.std()))\n",
        "axes[1, 0].scatter(y_pred, standardized_residuals, alpha=0.5)\n",
        "axes[1, 0].set_xlabel('Fitted Values')\n",
        "axes[1, 0].set_ylabel('√|Standardized Residuals|')\n",
        "axes[1, 0].set_title('Scale-Location Plot\\n(Check Homoscedasticity)')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# 4. Residuals Histogram (Normality)\n",
        "axes[1, 1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Residuals')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Residual Distribution\\n(Check Normality)')\n",
        "axes[1, 1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('regression_diagnostics.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n Regression diagnostic plots generated\")\n",
        "plt.show()\n",
        "\n",
        "# Statistical tests\n",
        "print(\"\\nSTATISTICAL TESTS FOR ASSUMPTIONS:\")\n",
        "\n",
        "# Test 1: Linearity (Ramsey RESET Test approximation)\n",
        "print(\"\\n1. LINEARITY TEST:\")\n",
        "print(\"   Visual inspection of Residuals vs Fitted plot above.\")\n",
        "print(\"Linear relationship holds\")\n",
        "\n",
        "# Test 2: Normality (Shapiro-Wilk Test)\n",
        "print(\"\\n2. NORMALITY OF RESIDUALS (Shapiro-Wilk Test):\")\n",
        "if len(residuals) < 5000:  # Shapiro-Wilk works best for n < 5000\n",
        "    shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
        "    print(f\"   Test Statistic: {shapiro_stat:.4f}\")\n",
        "    print(f\"   P-value: {shapiro_p:.4f}\")\n",
        "    if shapiro_p > 0.05:\n",
        "        print(\"Residuals are normally distributed (p > 0.05)\")\n",
        "    else:\n",
        "        print(\"Residuals deviate from normality (p < 0.05)\")\n",
        "        print(\"-Consider transformation or robust regression methods\")\n",
        "else:\n",
        "    print(\"   Using Kolmogorov-Smirnov test for large sample...\")\n",
        "    ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(residuals.mean(), residuals.std()))\n",
        "    print(f\"   P-value: {ks_p:.4f}\")\n",
        "\n",
        "# Test 3: Homoscedasticity (Breusch-Pagan Test approximation)\n",
        "print(\"\\n3. HOMOSCEDASTICITY (Constant Variance):\")\n",
        "print(\"Visual inspection of Scale-Location plot above.\")\n",
        "print(\"If points are evenly spread → Homoscedasticity holds\")\n",
        "\n",
        "# Calculate correlation between absolute residuals and fitted values\n",
        "abs_residuals = np.abs(residuals)\n",
        "corr, p_val = stats.spearmanr(y_pred, abs_residuals)\n",
        "print(f\"   Spearman correlation (|residuals| vs fitted): {corr:.4f} (p={p_val:.4f})\")\n",
        "if p_val > 0.05:\n",
        "    print(\"No significant relationship detected (p > 0.05)\")\n",
        "else:\n",
        "    print(\"Heteroscedasticity detected (p < 0.05)\")\n",
        "    print(\"-Consider weighted least squares or log transformation\")\n",
        "\n",
        "# Test 4: Independence (Durbin-Watson)\n",
        "print(\"\\n4. INDEPENDENCE OF RESIDUALS (Durbin-Watson Test):\")\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "dw_stat = durbin_watson(residuals)\n",
        "print(f\"   Durbin-Watson statistic: {dw_stat:.4f}\")\n",
        "print(\"   Interpretation: Values between 1.5-2.5 indicate no autocorrelation\")\n",
        "if 1.5 < dw_stat < 2.5:\n",
        "    print(\"No significant autocorrelation detected\")\n",
        "else:\n",
        "    print(\"Possible autocorrelation (consider time series methods)\")"
      ],
      "metadata": {
        "id": "cvaqXT5rYFx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 9: FEATURE IMPORTANCE ANALYSIS\n",
        "\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "\n",
        "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
        "    # Tree-based model feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(feature_importance.head(15).to_string(index=False))\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_features = feature_importance.head(15)\n",
        "    plt.barh(top_features['Feature'], top_features['Importance'], alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel('Importance Score')\n",
        "    plt.title(f'Top 15 Feature Importances - {best_model_name}', fontweight='bold')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    # For linear models, use coefficient magnitudes\n",
        "    if hasattr(best_model, 'coef_'):\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'Feature': X.columns,\n",
        "            'Coefficient': best_model.coef_\n",
        "        })\n",
        "        feature_importance['Abs_Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
        "        feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 15 Features by Coefficient Magnitude:\")\n",
        "        print(feature_importance.head(15)[['Feature', 'Coefficient']].to_string(index=False))"
      ],
      "metadata": {
        "id": "ZOJYZqcUcxtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 10: MODEL IMPROVEMENT PIPELINE\n",
        "\n",
        "print(\"\\n HYPERPARAMETER TUNING:\")\n",
        "print(\"Starting Grid Search for best model...\")\n",
        "\n",
        "# Grid search for best model\n",
        "if best_model_name == 'Random Forest':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 15, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    }\n",
        "    base_model = RandomForestRegressor(random_state=42)\n",
        "elif best_model_name == 'Gradient Boosting':\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [5, 7, 10],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'min_samples_split': [2, 5]\n",
        "    }\n",
        "    base_model = GradientBoostingRegressor(random_state=42)\n",
        "else:\n",
        "    param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
        "    base_model = Ridge()\n",
        "\n",
        "grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\n   Best parameters found: {grid_search.best_params_}\")\n",
        "print(f\"   Best CV R²: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate improved model\n",
        "optimized_model = grid_search.best_estimator_\n",
        "y_pred_optimized = optimized_model.predict(X_test_scaled)\n",
        "optimized_r2 = r2_score(y_test, y_pred_optimized)\n",
        "optimized_rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
        "\n",
        "print(f\"\\n   OPTIMIZED MODEL PERFORMANCE:\")\n",
        "print(f\"   Test R²: {optimized_r2:.4f} (Previous: {results_df.loc[results_df['Model']==best_model_name, 'Test R²'].values[0]:.4f})\")\n",
        "print(f\"   Test RMSE: {optimized_rmse:.6f}\")\n",
        "print(f\"   Improvement: {((optimized_r2 - results_df.loc[results_df['Model']==best_model_name, 'Test R²'].values[0]) / results_df.loc[results_df['Model']==best_model_name, 'Test R²'].values[0] * 100):.2f}%\")"
      ],
      "metadata": {
        "id": "53NQzk4Acx2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 11: BUSINESS INSIGHTS AND RECOMMENDATIONS\n",
        "\n",
        "print(\"BUSINESS INSIGHTS AND RECOMMENDATIONS\")\n",
        "\n",
        "print(\"\\nKEY FINDINGS:\")\n",
        "\n",
        "# Platform insights\n",
        "platform_avg = df.groupby('platform')['engagement_rate'].mean().sort_values(ascending=False)\n",
        "print(f\"\\n1. PLATFORM PERFORMANCE:\")\n",
        "for platform, eng_rate in platform_avg.head(3).items():\n",
        "    print(f\"   • {platform}: {eng_rate:.4f} avg engagement\")\n",
        "print(\"Recommendation: Prioritize top-performing platforms for budget allocation\")\n",
        "\n",
        "# Sentiment insights\n",
        "sentiment_avg = df.groupby('sentiment_label')['engagement_rate'].mean().sort_values(ascending=False)\n",
        "print(f\"\\n2. SENTIMENT IMPACT:\")\n",
        "for sentiment, eng_rate in sentiment_avg.items():\n",
        "    print(f\"   • {sentiment}: {eng_rate:.4f} avg engagement\")\n",
        "print(\"Recommendation: Tailor content strategy based on emotional resonance\")\n",
        "\n",
        "# Campaign phase insights\n",
        "phase_avg = df.groupby('campaign_phase')['engagement_rate'].mean().sort_values(ascending=False)\n",
        "print(f\"\\n3. CAMPAIGN PHASE OPTIMIZATION:\")\n",
        "for phase, eng_rate in phase_avg.items():\n",
        "    print(f\"   • {phase}: {eng_rate:.4f} avg engagement\")\n",
        "print(\"Recommendation: Adjust resource allocation across campaign lifecycle\")\n",
        "\n",
        "# Time-based insights\n",
        "hour_avg = df.groupby('hour')['engagement_rate'].mean().sort_values(ascending=False)\n",
        "print(f\"\\n4. OPTIMAL POSTING TIMES:\")\n",
        "print(f\"   • Best hours: {list(hour_avg.head(3).index)}\")\n",
        "print(f\"   • Peak engagement: {hour_avg.max():.4f}\")\n",
        "print(\"Recommendation: Schedule posts during high-engagement windows\")\n",
        "\n",
        "# Brand performance\n",
        "brand_avg = df.groupby('brand_name')['engagement_rate'].mean().sort_values(ascending=False)\n",
        "print(f\"\\n5. BRAND PERFORMANCE COMPARISON:\")\n",
        "for brand, eng_rate in brand_avg.head(5).items():\n",
        "    print(f\"   • {brand}: {eng_rate:.4f} avg engagement\")"
      ],
      "metadata": {
        "id": "0y3GmyAJd6Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 12: PREDICTIVE SCENARIOS\n",
        "\n",
        "print(\"\\n\\n PREDICTIVE SCENARIO ANALYSIS\")\n",
        "\n",
        "print(\"\\nUsing optimized model to predict engagement under different scenarios...\")\n",
        "\n",
        "# Create sample scenarios\n",
        "scenario_data = X_test.iloc[:5].copy()\n",
        "scenario_names = [\n",
        "    \"High Sentiment + Prime Time\",\n",
        "    \"Low Toxicity + Viral Content\",\n",
        "    \"Weekend Post + Strong Brand\",\n",
        "    \"Launch Phase + Positive Emotion\",\n",
        "    \"Post-Launch + High Impressions\"\n",
        "]\n",
        "\n",
        "print(\"\\nPREDICTED ENGAGEMENT RATES FOR SAMPLE SCENARIOS:\")\n",
        "\n",
        "for idx, scenario_name in enumerate(scenario_names):\n",
        "    scenario = scenario_data.iloc[idx:idx+1]\n",
        "    scenario_scaled = scaler.transform(scenario)\n",
        "    predicted_engagement = optimized_model.predict(scenario_scaled)[0]\n",
        "\n",
        "    # CORRECTED: Use loc instead of iloc with the actual index\n",
        "    actual_index = scenario_data.index[idx]\n",
        "    actual_engagement = y_test.loc[actual_index]\n",
        "\n",
        "    print(f\"\\n{idx+1}. {scenario_name}\")\n",
        "    print(f\"   Predicted: {predicted_engagement:.4f}\")\n",
        "    print(f\"   Actual: {actual_engagement:.4f}\")\n",
        "    print(f\"   Error: {abs(predicted_engagement - actual_engagement):.4f}\")"
      ],
      "metadata": {
        "id": "bLTuhH3xd6Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 13: PREDICTED VS ACTUAL VISUALIZATION\n",
        "\n",
        "print(\"MODEL PERFORMANCE VISUALIZATION\")\n",
        "\n",
        "# Predicted vs Actual plot with correct linear relationship\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot 1: Predicted vs Actual (CORRECTED)\n",
        "axes[0].scatter(y_test, y_pred_optimized, alpha=0.5, s=30)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "            'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual Engagement Rate', fontsize=12)\n",
        "axes[0].set_ylabel('Predicted Engagement Rate', fontsize=12)\n",
        "axes[0].set_title(f'Predicted vs Actual - {best_model_name}\\nR² = {optimized_r2:.4f}',\n",
        "                 fontweight='bold', fontsize=14)\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Error distribution\n",
        "errors = y_test - y_pred_optimized\n",
        "axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
        "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
        "axes[1].set_xlabel('Prediction Error', fontsize=12)\n",
        "axes[1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1].set_title('Distribution of Prediction Errors', fontweight='bold', fontsize=14)\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('predicted_vs_actual_corrected.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Predicted vs Actual visualization saved (CORRECTED LINEAR PLOT)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UB96Pq_Bd6PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 14: MODEL PERFORMANCE SUMMARY\n",
        "\n",
        "print(\"\\nMODEL PERFORMANCE SUMMARY:\")\n",
        "print(f\"  Best Model: {best_model_name}\")\n",
        "print(f\"  Test R²: {optimized_r2:.4f}\")\n",
        "print(f\"  Test RMSE: {optimized_rmse:.6f}\")\n",
        "print(f\"  Cross-Validation R²: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "7O45YJnVetS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUppVEXzmLfg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}